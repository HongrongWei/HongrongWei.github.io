---
permalink: /
title: "Biography"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am currently a researcher at the Smart Health Department of SenseTime, focusing on medical AI algorithms.
I received both my Bachelor's and Master's degrees in Biomedical Engineering from Shenzhen University, 
where I worked on medical image segmentation and registration in the Medical Ultrasound Image Computing Lab, led by Professor Dong Ni.
Before joining SenseTime, I interned at the Tencent Jarvis Research Center, developing self-supervised algorithms for medical image segmentation.

# Project


<div style="display: flex; align-items: flex-start; margin-bottom: 1.5em;">

  <!-- Â∑¶‰æßÂõæÁâá -->
  <div style="flex: 0 0 160px; margin-right: 20px;">
    <img src="/images/MCLAS_v2.png" alt="project image" style="width: 100%; border-radius: 8px; border: 1px solid #ccc;">
  </div>

  <!-- Âè≥‰æßÊñáÂ≠ó -->
  <div style="flex: 1;">
    <p style="margin: 0; font-size: 15px; font-weight: bold;">
      Co-learning of Appearance and Shape for Precise Ejection Fraction Estimation from Echocardiographic Sequences
    </p>
    <p style="margin: 0 0 10px 0; font-size: 13.5px;">
      <strong>Hongrong Wei</strong>, Junqiang Ma, Yongjin Zhou, Wufeng Xue<sup>*</sup>, Dong Ni<sup>*</sup>
    </p>
    <p style="margin: 2px 0 5px 0; font-size: 14px; font-style: italic;">
      Medical Image Analysis, Feb. 2023
    </p>

    <!-- ÈìæÊé•ÊåâÈíÆ -->
    <p style="margin: 0;">
      üîó <a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841522003140" target="_blank">[Paper]</a>
      &nbsp;|&nbsp;
      üìΩÔ∏è <a href="https://docs.google.com/presentation/d/1KKNQotp5UvlFZur5TJqgwO4XwMqdQxAv/edit?usp=drive_link&ouid=104984256786708680802&rtpof=true&sd=true" target="_blank">[BME2021-Slide]</a>
    </p>
  </div>

</div>



<div style="display: flex; align-items: flex-start; margin-bottom: 1.5em;">

  <!-- Â∑¶‰æßÂõæÁâá -->
  <div style="flex: 0 0 160px; margin-right: 20px;">
    <img src="/images/CLAS.png" alt="project image" style="width: 100%; border-radius: 8px; border: 1px solid #ccc;">
  </div>

  <!-- Âè≥‰æßÊñáÂ≠ó -->
  <div style="flex: 1;">
    <p style="margin: 0; font-size: 15px; font-weight: bold;">
      Temporal-Consistent Segmentation of Echocardiography with Co-Learning from Appearance and Shape
    </p>
    <p style="margin: 0 0 10px 0; font-size: 13.5px;">
      <strong>Hongrong Wei</strong>, Heng Cao, Yiqin Cao, Yongjin Zhou, Wufeng Xue<sup>*</sup>, Dong Ni, Shuo Li
    </p>
    <p style="margin: 2px 0 5px 0; font-size: 14px; font-style: italic;">
      Medical Image Computing and Computer Assisted Intervention (MICCAI), Sep. 2020
    </p>

    <!-- ÈìæÊé•ÊåâÈíÆ -->
    <p style="margin: 0;">
      üîó <a href="https://link.springer.com/chapter/10.1007/978-3-030-59713-9_60" target="_blank">[Paper]</a>
      &nbsp;|&nbsp;
      üíª <a href="https://github.com/tumuzhuantoujun/CLAS-Pytorch" target="_blank">[Code]</a>
      &nbsp;|&nbsp;
      üìΩÔ∏è <a href="https://docs.google.com/presentation/d/105LcKMORfRmEWY4mm6QtJwjWjFET2rWH/edit?usp=drive_link&ouid=104984256786708680802&rtpof=true&sd=true" target="_blank">[Slide]</a>
    </p>
  </div>

</div>


<div style="display: flex; align-items: flex-start; margin-bottom: 1.5em;">

  <!-- Â∑¶‰æßÂõæÁâá -->
  <div style="flex: 0 0 160px; margin-right: 20px;">
    <img src="/images/SDT.png" alt="project image" style="width: 100%; border-radius: 8px; border: 1px solid #ccc;">
  </div>

  <!-- Âè≥‰æßÊñáÂ≠ó -->
  <div style="flex: 1;">
    <p style="margin: 0; font-size: 15px; font-weight: bold;">
      Reducing Domain Gaps for Echocardiogram Video Segmentation via Shape-Driven Tracking
    </p>
    <p style="margin: 0 0 10px 0; font-size: 13.5px;">
      <strong>Hongrong Wei</strong>, Na Wang, Tian Shen, Shaoting Zhang
    </p>
    <p style="margin: 2px 0 5px 0; font-size: 14px; font-style: italic;">
      Under review
    </p>

  </div>

</div>


<div style="display: flex; align-items: flex-start; margin-bottom: 1.5em;">

  <!-- Â∑¶‰æßÂõæÁâá -->
  <div style="flex: 0 0 160px; margin-right: 20px;">
    <img src="/images/heart4d.png" alt="project image" style="width: 100%; border-radius: 8px; border: 1px solid #ccc;">
  </div>

  <!-- Âè≥‰æßÈ°πÁõÆÊèèËø∞ -->
  <div style="flex: 1; font-size: 14px; line-height: 1.5;">
    <p>
      This project proposes a 4D cardiac mesh generation framework that captures both spatial structure and temporal dynamics, aiming to support cardiac function assessment and preoperative planning.
      By leveraging 3D cardiac CT and echocardiographic sequences, we integrate latent diffusion and autoregressive modeling to synthesize temporally coherent 3D meshes across the cardiac cycle.
    </p>

  </div>

</div>

<div style="display: flex; align-items: flex-start; margin-bottom: 1.5em;">

  <!-- Â∑¶‰æßÂõæÁâá -->
  <div style="flex: 0 0 160px; margin-right: 20px;">
    <img src="/images/PE.png" alt="project image" style="width: 100%; border-radius: 8px; border: 1px solid #ccc;">
  </div>

  <!-- Âè≥‰æßÈ°πÁõÆÊèèËø∞ -->
  <div style="flex: 1; font-size: 14px; line-height: 1.5;">
    <p>
        Pulmonary embolism (PE) is a life-threatening condition requiring early and accurate diagnosis.
        We propose a deep learning framework combining embolus segmentation, center detection, and anatomical constraints, 
        with a Graph Attention Network (GAT) to reduce false positives via global vascular context.
    </p>

  </div>

</div>

<div style="display: flex; align-items: flex-start; margin-bottom: 1.5em;">

  <!-- Â∑¶‰æßÂõæÁâá -->
  <div style="flex: 0 0 160px; margin-right: 20px;">
    <img src="/images/uro.png" alt="project image" style="width: 100%; border-radius: 8px; border: 1px solid #ccc;">
  </div>

  <!-- Âè≥‰æßÈ°πÁõÆÊèèËø∞ -->
  <div style="flex: 1; font-size: 14px; line-height: 1.5;">
    <p>
        This project performs 3D reconstruction of the urinary system from CT scans using nn-Unet, enabling precise segmentation of organs and lesions. 
        It supports automated diagnosis of ureteral dilation, and integrates CenterNet and U-Net for kidney tumor and cyst detection, aiding surgical planning.
    </p>

  </div>

</div>

<div style="display: flex; align-items: flex-start; margin-bottom: 1.5em;">

  <!-- Â∑¶‰æßÂõæÁâá -->
  <div style="flex: 0 0 160px; margin-right: 20px;">
    <img src="/images/nodule.png" alt="project image" style="width: 100%; border-radius: 8px; border: 1px solid #ccc;">
  </div>

  <!-- Âè≥‰æßÈ°πÁõÆÊèèËø∞ -->
  <div style="flex: 1; font-size: 14px; line-height: 1.5;">
    <p>
        This project develops a 2.5D multi-channel Yolo-v7 model based on 3D thin/thick CT sequences for detecting major pulmonary lesions. 
        Additionally, a multi-label classification network identifies 11 typical nodule characteristics (e.g., lobulation, spiculation, vacuole) critical for malignancy assessment. 
        A partial label learning strategy is employed to dynamically refine noisy label confidence, improving overall detection accuracy.
    </p>

  </div>

</div>


<div style="display: flex; align-items: flex-start; margin-bottom: 1.5em;">

  <!-- Â∑¶‰æßÂõæÁâá -->
  <div style="flex: 0 0 160px; margin-right: 20px;">
    <img src="/images/CT_denoise.png" alt="project image" style="width: 100%; border-radius: 8px; border: 1px solid #ccc;">
  </div>

  <!-- Âè≥‰æßÈ°πÁõÆÊèèËø∞ -->
  <div style="flex: 1; font-size: 14px; line-height: 1.5;">
    <p>
       This project proposes an unsupervised LDCT synthesis and denoising model based on StarGAN v2, capable of generating and denoising LDCT images without paired NDCT/LDCT data. 
       The model leverages a Mapping Network or Style Encoder to extract style vectors representing noise patterns at different dose levels, 
       which are injected or removed via AdaIN modules within the generator to control noise characteristics.
    </p>
  </div>

</div>






